{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [3, 128, 128]\n",
    "        self.cnn = models.efficientnet_v2_s(weights = models.EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "        self.fc = nn.Linear(1000 , 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = (440,310)\n",
    "image_size = (220,105)\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomAdjustSharpness(1.5, p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.05),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizex , img_sizey = 1280 , 720\n",
    "crop_xt , crop_yt = 200 , 100\n",
    "crop_xd , crop_yd = 200 , 0\n",
    "resize_factor = 4\n",
    "new_sizex = int(( img_sizex - crop_xt - crop_xd ) / resize_factor )\n",
    "new_sizey = int(( img_sizey - crop_yt - crop_yd ) / resize_factor )\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_video_frame(vid_path , tfm = test_tfm):\n",
    "    vid_cap = cv2.VideoCapture(vid_path)\n",
    "    frames = []\n",
    "    \n",
    "    while vid_cap.isOpened():\n",
    "        ret, frame = vid_cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "#         print(ret)\n",
    "\n",
    "        frame = frame[crop_yt : img_sizey-crop_yd , crop_xt : img_sizex - crop_xd]\n",
    "        frame = cv2.resize(frame, (new_sizex , new_sizey), interpolation=cv2.INTER_AREA)\n",
    "        frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        frame = tfm(frame)\n",
    "        #         frame = torch.tensor(frame)\n",
    "#         frame = torch.transpose(frame,0,1)\n",
    "        \n",
    "        frames.append(frame)\n",
    "        \n",
    "    return torch.stack(frames, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, root, frame_transform=None, video_transform=None):\n",
    "        super(VideoDataset).__init__()\n",
    "\n",
    "        video_path = Path(root).glob('*')\n",
    "\n",
    "        self.filename = []\n",
    "    \n",
    "        for video in video_path:\n",
    "            self.filename.append(f\"{video}/{video.name}.mp4\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        temp_video = None\n",
    "        last_path = \"\"\n",
    "        \n",
    "        for video_path in self.filename:\n",
    "\n",
    "            video  = get_video_frame(video_path)\n",
    "            pts = 1\n",
    "            for subvideo in video:\n",
    "                    \n",
    "                output = {\n",
    "                    'path': video_path.split('/')[-1],\n",
    "                    'pts' : pts ,\n",
    "                    'img': subvideo,\n",
    "                }\n",
    "                pts+=1\n",
    "                    \n",
    "                yield output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_dataset = VideoDataset(\"/kaggle/input/badminton/inference/inference\")\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036a59068d64467a8a9283d7472e5d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'paths': ['00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4', '00114.mp4'], 'pts': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]}\n"
     ]
    }
   ],
   "source": [
    "model_best = Classifier().to(device)\n",
    "# model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
    "model_best.eval()\n",
    "\n",
    "preds = {'labels' : [],\n",
    "         'paths' : [],\n",
    "         'pts' :[],\n",
    "        }\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data_dic in tqdm(inference_loader):\n",
    "#         print(data_dic['img'].shape)\n",
    "        pred = model_best(data_dic['img'])\n",
    "#         torch.cat((pred , data_dic['path']))\n",
    "    \n",
    "        label = np.argmax(pred.cpu().data.numpy(), axis=1)\n",
    "        path = data_dic['path']\n",
    "        pts = data_dic['pts']\n",
    "        \n",
    "        preds['labels'] +=label.tolist()\n",
    "        preds['paths'] += path\n",
    "        preds['pts'] += pts.tolist()\n",
    "        #         prediction = np.append(prediction , pred_path )\n",
    "        break\n",
    "print(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VideoName', 'ShotSeq', 'HitFrmae', 'Hitter', 'RoundHead', 'Backhand',\n",
      "       'BallHeight', 'LandingX', 'LandingY', 'HitterLocationX',\n",
      "       'HitterLocationY', 'DefenderLocationX', 'DefenderLocationY', 'BallType',\n",
      "       'Winner'],\n",
      "      dtype='object')\n",
      "['00114.mp4', 1, 1, 'A', 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 'X']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (15, 1), indices imply (15, 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_27/2121508698.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ShotSeq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"A\"\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mdf_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"A\"\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     28\u001b[0m             \u001b[0mdf_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m  \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ShotSeq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"A\"\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n",
      "\u001b[1;32m    715\u001b[0m                         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    716\u001b[0m                         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 717\u001b[0;31m                         \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    718\u001b[0m                     )\n",
      "\u001b[1;32m    719\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n",
      "\u001b[1;32m    322\u001b[0m     )\n",
      "\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n",
      "\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (15, 1), indices imply (15, 15)"
     ]
    }
   ],
   "source": [
    "# result = pd.read_csv(\"/kaggle/input/badminton/dataset/dataset/valid/labels/00001.csv\")\n",
    "# result = {'VideoName' :[],\n",
    "#          'ShotSeq' : [],\n",
    "#          'HitFrmae' : [],\n",
    "#          'Hitter' : [],\n",
    "#          \"RoundHead\" : [],\n",
    "#          \"Backhand\" : [],\n",
    "#          \"BallHeight\" : [],\n",
    "#          \"LandingX\":[],\n",
    "#          \"LandingY\":[],\n",
    "#          \"HitterLocationX\":[],\n",
    "#          \"HitterLocationY\":[],\n",
    "#          \"DefenderLocationX\":[],\n",
    "#          \"DefenderLocationY\":[],\n",
    "#          \"BallType\":[],\n",
    "#          \"Winner\":[]\n",
    "result = pd.DataFrame(columns=['VideoName','ShotSeq','HitFrmae','Hitter',\"RoundHead\",\"Backhand\",\"BallHeight\",\"LandingX\",\"LandingY\",\"HitterLocationX\",\"HitterLocationY\",\n",
    "         \"DefenderLocationX\",\"DefenderLocationY\",\"BallType\",\"Winner\"])\n",
    "print(result.columns)  \n",
    "\n",
    "for idx in range(len(preds['labels'])):\n",
    "    if pred_labels[idx] == 1:\n",
    "        df = result.loc[result['VideoName'] == preds['paths'][idx]]\n",
    "        if pd.isna( df['ShotSeq'].max() ):\n",
    "            print(([preds['paths'][idx] , 1 , preds['pts'][idx] , \"A\"  , 1 , 1 , 1 , 1 ,1 ,1 ,1 ,1,1,1,'X']))\n",
    "            df_add = pd.DataFrame([preds['paths'][idx] , 1 , preds['pts'][idx] , \"A\"  , 1 , 1 , 1 , 1 ,1 ,1 ,1 ,1,1,1,'X'] , columns = result.columns)\n",
    "        else:\n",
    "            df_add = pd.DataFrame([preds['paths'][idx] ,  df['ShotSeq'].max()+1 , preds['pts'][idx] , \"A\"  , 1 , 1 , 1 , 1 ,1 ,1 ,1 ,1,1,1,'X'] , columns = result.columns)\n",
    "        \n",
    "        result = pd.concat([result , df_add])\n",
    "    break\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
