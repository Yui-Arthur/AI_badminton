{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-01T06:45:31.263962Z","iopub.status.busy":"2023-05-01T06:45:31.262971Z","iopub.status.idle":"2023-05-01T06:45:34.207184Z","shell.execute_reply":"2023-05-01T06:45:34.206172Z","shell.execute_reply.started":"2023-05-01T06:45:31.263909Z"},"trusted":true},"outputs":[],"source":["import gc\n","import numpy as np\n","import pandas as pd\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from torchvision import models\n","from PIL import Image\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","# This is for the progress bar.\n","from tqdm.auto import tqdm\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T06:45:34.209799Z","iopub.status.busy":"2023-05-01T06:45:34.209354Z","iopub.status.idle":"2023-05-01T06:45:34.309792Z","shell.execute_reply":"2023-05-01T06:45:34.308749Z","shell.execute_reply.started":"2023-05-01T06:45:34.209769Z"},"trusted":true},"outputs":[],"source":["myseed = 1091102  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T07:29:15.014168Z","iopub.status.busy":"2023-05-03T07:29:15.013687Z","iopub.status.idle":"2023-05-03T07:29:15.024190Z","shell.execute_reply":"2023-05-03T07:29:15.022796Z","shell.execute_reply.started":"2023-05-03T07:29:15.014126Z"},"trusted":true},"outputs":[],"source":["class BadmintonDataset(Dataset):\n","\n","    def __init__(self,path,tfm,files = None):\n","        super(BadmintonDataset).__init__()\n","        self.path = path\n","        \n","        if files != None:\n","            self.files = files\n","        else:\n","            self.files = [] \n","            for i in Path(path).glob('*'):\n","                self.files.append(i)\n","            \n","        self.transform = tfm\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = str(self.files[idx])\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        \n","        \n","        if fname.split(\"_\")[-1].strip('.jpg') == 'x':\n","            label = 0\n","        else:\n","            label = 1\n","            \n","        return im,label"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T07:09:49.228278Z","iopub.status.busy":"2023-05-03T07:09:49.227838Z","iopub.status.idle":"2023-05-03T07:09:49.236375Z","shell.execute_reply":"2023-05-03T07:09:49.235158Z","shell.execute_reply.started":"2023-05-03T07:09:49.228240Z"},"trusted":true},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","        # input 維度 [3, 128, 128]\n","        self.cnn = models.efficientnet_v2_s(weights = models.EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n","        self.fc = nn.Linear(1000 , 2)\n","        \n","    def forward(self, x):\n","        out = self.cnn(x)\n","        out = self.fc(out)\n","        return out"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T07:21:52.209399Z","iopub.status.busy":"2023-05-03T07:21:52.208931Z","iopub.status.idle":"2023-05-03T07:21:52.217026Z","shell.execute_reply":"2023-05-03T07:21:52.215861Z","shell.execute_reply.started":"2023-05-03T07:21:52.209357Z"},"trusted":true},"outputs":[],"source":["# image_size = (440,310)\n","image_size = (220,105)\n","test_tfm = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.ToTensor(),\n","])\n","\n","train_tfm = transforms.Compose([\n","    transforms.Resize(image_size),\n","    transforms.RandomAdjustSharpness(1.5, p=0.5),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomRotation(10),\n","    transforms.ColorJitter(0.2,0.2,0.2,0.05),\n","    transforms.ToTensor(),\n","])"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T07:22:45.555687Z","iopub.status.busy":"2023-05-03T07:22:45.555199Z","iopub.status.idle":"2023-05-03T07:22:46.112694Z","shell.execute_reply":"2023-05-03T07:22:46.111461Z","shell.execute_reply.started":"2023-05-03T07:22:45.555645Z"},"trusted":true},"outputs":[],"source":["# \"cuda\" only when GPUs are available.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Initialize a model, and put it on the device specified.\n","model = Classifier().to(device)\n","batch_size = 64\n","n_epochs = 10\n","patience = 10\n","criterion = nn.CrossEntropyLoss(label_smoothing = 0.05)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n","TTA_num = 5\n","TTA_ratio = 0.8\n","train_valid_ratio = 0.9\n","video_num = 800\n","_exp_name = \"hit_model\"\n","\n","# read_model = \"/kaggle/input/models/sample_best.ckpt\"\n","\n","# if read_model != None:\n","#     model.load_state_dict(torch.load(read_model))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T06:45:39.047654Z","iopub.status.busy":"2023-05-01T06:45:39.047220Z","iopub.status.idle":"2023-05-01T06:45:43.560094Z","shell.execute_reply":"2023-05-01T06:45:43.559020Z","shell.execute_reply.started":"2023-05-01T06:45:39.047610Z"},"trusted":true},"outputs":[],"source":["# files =  [os.path.join(\"/kaggle/input/badminton/dataset/train/images\",x) for x in os.listdir(\"/kaggle/input/badminton/dataset/train/images\") if x.endswith(\".jpg\")]\n","# train_file = []\n","# valid_file = []\n","\n","# files.sort()\n","\n","# for file in files:\n","    \n","#     if int(file.split('/')[-1].split(\"_\")[0].strip('0')) <= video_num * train_valid_ratio:\n","#         train_file.append(file)\n","#     else:\n","#         valid_file.append(file)\n","    \n","# train_file.sort()\n","# valid_file.sort()\n","\n","# del files\n","# gc.collect()\n","\n"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T07:29:19.388380Z","iopub.status.busy":"2023-05-03T07:29:19.387921Z","iopub.status.idle":"2023-05-03T07:29:19.943024Z","shell.execute_reply":"2023-05-03T07:29:19.941800Z","shell.execute_reply.started":"2023-05-03T07:29:19.388340Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["40741\n","5686\n","torch.Size([3, 220, 105])\n"]}],"source":["train_set = BadmintonDataset(\"/kaggle/input/badminton/dataset/dataset/train/images\", tfm=train_tfm )\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","valid_set = BadmintonDataset(\"/kaggle/input/badminton/dataset/dataset/valid/images\", tfm=test_tfm )\n","valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","\n","print(len(train_set))\n","print(len(valid_set))\n","\n","_ , label = valid_set[0]\n","print(_.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-01T06:45:43.603260Z","iopub.status.busy":"2023-05-01T06:45:43.602884Z","iopub.status.idle":"2023-05-01T06:58:29.276356Z","shell.execute_reply":"2023-05-01T06:58:29.274343Z","shell.execute_reply.started":"2023-05-01T06:45:43.603221Z"},"trusted":true},"outputs":[],"source":["# Initialize trackers, these are not parameters and should not be changed\n","stale = 0\n","best_acc = 0\n","train_acc_record = []\n","train_loss_record = []\n","valid_acc_record = []\n","valid_loss_record = []\n","\n","for epoch in range(n_epochs):\n","\n","    # ---------- Training ----------\n","    # Make sure the model is in train mode before training.\n","    model.train()\n","\n","    # These are used to record information in training.\n","    train_loss = []\n","    train_accs = []\n","\n","    for batch in tqdm(train_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        #imgs = imgs.half()\n","        #print(imgs.shape,labels.shape)\n","\n","        # Forward the data. (Make sure data and model are on the same device.)\n","        logits = model(imgs.to(device))\n","\n","        # Calculate the cross-entropy loss.\n","        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n","        loss = criterion(logits, labels.to(device))\n","\n","        # Gradients stored in the parameters in the previous step should be cleared out first.\n","        optimizer.zero_grad()\n","\n","        # Compute the gradients for parameters.\n","        loss.backward()\n","\n","        # Clip the gradient norms for stable training.\n","        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","\n","        # Update the parameters with computed gradients.\n","        optimizer.step()\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        train_loss.append(loss.item())\n","        train_accs.append(acc)\n","        \n","    train_loss = sum(train_loss) / len(train_loss)\n","    train_acc = sum(train_accs) / len(train_accs)\n","    \n","    train_acc_record.append(train_acc.to('cpu'))\n","    train_loss_record.append(train_loss)\n","    # Print the information.\n","    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n","\n","    # ---------- Validation ----------\n","    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","    model.eval()\n","\n","    # These are used to record information in validation.\n","    valid_loss = []\n","    valid_accs = []\n","\n","    # Iterate the validation set by batches.\n","    for batch in tqdm(valid_loader):\n","\n","        # A batch consists of image data and corresponding labels.\n","        imgs, labels = batch\n","        #imgs = imgs.half()\n","\n","        # We don't need gradient in validation.\n","        # Using torch.no_grad() accelerates the forward process.\n","        with torch.no_grad():\n","            logits = model(imgs.to(device))\n","\n","        # We can still compute the loss (but not the gradient).\n","        loss = criterion(logits, labels.to(device))\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        # Record the loss and accuracy.\n","        valid_loss.append(loss.item())\n","        valid_accs.append(acc)\n","        #break\n","\n","    # The average loss and accuracy for entire validation set is the average of the recorded values.\n","    valid_loss = sum(valid_loss) / len(valid_loss)\n","    valid_acc = sum(valid_accs) / len(valid_accs)\n","    \n","    valid_acc_record.append(valid_acc.to('cpu'))\n","    valid_loss_record.append(valid_loss)\n","\n","    # Print the information.\n","    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # update logs\n","    if valid_acc > best_acc:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n","    else:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","    # save models\n","    if valid_acc > best_acc:\n","        print(f\"Best model found at epoch {epoch}, saving model\")\n","        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","        best_acc = valid_acc\n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale > patience:\n","            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-05-01T06:58:29.277497Z","iopub.status.idle":"2023-05-01T06:58:29.280928Z","shell.execute_reply":"2023-05-01T06:58:29.280745Z","shell.execute_reply.started":"2023-05-01T06:58:29.280721Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot([*range(1,len(train_acc_record)+1)] , train_acc_record , label = \"training\")\n","plt.plot([*range(1,len(train_acc_record)+1)] , valid_acc_record , label = \"validation\")\n","\n","plt.xticks(np.arange(0, n_epochs+1, 5))\n","plt.legend(loc=\"upper left\")\n","\n","plt.savefig('acc.png')\n","plt.show()\n","\n","\n","plt.plot([*range(1,len(train_acc_record)+1)] , train_loss_record , label = \"training\")\n","plt.plot([*range(1,len(train_acc_record)+1)] , valid_loss_record , label = \"valiidation\")\n","\n","plt.xticks(np.arange(0, n_epochs+1, 5))\n","plt.legend(loc=\"upper left\")\n","\n","plt.savefig('loss.png')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
